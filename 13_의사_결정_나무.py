# -*- coding: utf-8 -*-
"""13. 의사 결정 나무.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jskz8GO1K0dSUI49io5Scpy9w4cZ2asn

# **1. bike 데이터셋**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

bike_df = pd.read_csv('/content/drive/MyDrive/컴퓨터비전_시즌2/3. 데이터 분석/Data/bike.csv')
bike_df

bike_df.info()

"""* datetime: 날짜
* count: 대여 개수
* holiday: 휴일
* workingday: 근무일
* temp: 기온
* feels_like: 체감온도
* temp_min: 최저온도
* temp_max: 최고온도
* pressure: 기압
* humidity: 습도
* wind_speed: 풍속
* wind_deg: 풍향
* rain_1h: 1시간당 내리는 비의 양
* snow_1h: 1시간당 내리는 눈의 양
* clouds_all: 구름의 양
* weather_main: 날씨
"""

bike_df.describe() # 통계값 확인

sns.displot(bike_df['count'])

sns.boxplot(y=bike_df['count']) # 이상치는 없는듯

sns.scatterplot(x='feels_like', y='count', data=bike_df, alpha=0.3) # 체감온도에 따른 대여수

sns.scatterplot(x='pressure', y='count', data=bike_df, alpha=0.3) # 기압에 따른 대여수
# 기압에 영향을 받음 -> 날씨, 시간 등에도 영향을 받음

sns.scatterplot(x='wind_speed', y='count', data=bike_df, alpha=0.3) # 풍속에 따른 대여수

sns.scatterplot(x='wind_deg', y='count', data=bike_df, alpha=0.3) # 풍향에 따른 대여수

bike_df.isna().sum() # 결측치 / rain_1h, snow_1h 에만 결측치 있음

bike_df = bike_df.fillna(0) # 전체 결측치 0으로 채우기
bike_df.isna().sum()

bike_df.info()

bike_df['datetime'] = pd.to_datetime(bike_df['datetime'])
bike_df.info()

bike_df.head() # 년월일시 확인 가능

bike_df['year'] = bike_df['datetime'].dt.year
bike_df['month'] = bike_df['datetime'].dt.month
bike_df['hour'] = bike_df['datetime'].dt.hour
bike_df.head()

bike_df['date'] = bike_df['datetime'].dt.date
bike_df.head()

plt.figure(figsize=(14, 4))
sns.lineplot(x='date', y='count', data=bike_df)
plt.xticks(rotation=45)
plt.show()

bike_df[bike_df['year'] == 2019].groupby('month')['count'].mean() # 2019년 달마다 평균 확인

bike_df[bike_df['year'] == 2020].groupby('month')['count'].mean() # 2020년 달마다 평균 확인 -> 4월 없음
# 2020 4월 전, 2020 4월 이후 1년(코로나 예상), 그 이후 1년 이렇게 3개로 분류해보기

# covid
# ~ 2020-04-01: precovid
# 2020-04-01 ~ 2021-04-01: covid
# 2021-04-01 ~ : postcovid
def covid(date):
  if str(date) < '2020-04-01':
    return 'precovid'
  elif str(date) < '2021-04-01':
    return 'covid'
  else:
    return 'postcovid'

bike_df['date'].apply(covid)

bike_df['covid'] = bike_df['date'].apply(
    lambda date: 'precovid' if str(date) < '2020-04-01'
                            else 'covid' if str(date) < '2021-04-01'
                            else 'postcovid'
) # 람다함수로 apply 해보기

bike_df

# season
# 12월~2월: winter
# 3월~5월: spring
# 6월~8월: summer
# 9월~11월: fall
bike_df['season'] = bike_df['month'].apply(
    lambda x: 'winter' if x == 12
                            else 'fall' if x >= 9
                            else 'summer' if x >= 6
                            else 'spring' if x >= 3
                            else 'winter'
)

bike_df[['month', 'season']]

# day_night
# 21시 ~ : night
# 19시 ~ : late evening
# 17시 ~ : early evening
# 15시 ~ : late afternoon
# 13시 ~ : early afternoon
# 11시 ~ : late morning
# 6시 ~ : early morning

bike_df['day_night'] = bike_df['hour'].apply(
    lambda x: 'night' if x >= 21
    else 'late evening' if x >= 19
    else 'early evening' if x >= 17
    else 'late afternoon' if x >= 15
    else 'early afternoon' if x >= 13
    else 'late morning' if x >= 11
    else 'early morning' if x >= 6
    else 'night'
)

bike_df.head()

bike_df.drop(['datetime', 'month', 'date', 'hour'], axis=1, inplace=True)
bike_df.head()

bike_df.info()

for i in ['weather_main', 'covid', 'season', 'day_night']:
  print(i, bike_df[i].nunique())

bike_df['weather_main'].unique()

bike_df = pd.get_dummies(bike_df, columns = ['weather_main', 'covid', 'season', 'day_night']) # 원핫인코딩
bike_df.head()

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(bike_df.drop('count', axis=1), bike_df['count'], test_size=0.2, random_state=2024)

X_train.shape, y_train.shape

X_test.shape, y_test.shape

"""# **2. 의사 결정 나무(Decision Tree)**
* 데이터를 분석하고 패턴을 파악하여 결정 규칙을 나무 구조로 나타낸 기계학습 알고리즘
* 간단하고 강력한 모델 중 하나로, 분류와 회귀 문제에 모두 사용
* 엔트로피: 데이터의 불확실성을 측정. 특정 속성으로 데이터를 나누었을 때 엔트로피가 얼마나 감소하는지를 계산하여 정보를 얻음. 정보 이득이 높은 속성을 선택하여 데이터를 나누게 됨
* 지니계수: 데이터의 불순도를 측정하는 또 다른 방법. 임의로 선택된 두 개의 요소가 서로 다른 클래스에 속할 확률을 나타냄. 지니 불순도가 낮을수록 데이터가 잘 분리된 것
* 의사 결정 나무는 오버피팅이 매우 잘 일어남
  * 오버피팅(과적합): 학습데이터에서는 정확하나 테스트데이터에서는 성과가 나쁜 현상을 말함.
  * 오버피팅을 방지하는 방법
    * 사전 가지치기: 나무가 다 자라기 전에 알고리즘을 멈추는 방법
    * 사후 가지치기: 나무를 끝까지 다 돌린 후에 밑에서부터 가지를 쳐 나가는 방법
"""

from sklearn.tree import DecisionTreeRegressor

dtr = DecisionTreeRegressor(random_state=2024)
# 하이퍼 파라미터: 모델의 기능 조절. 최근 모델들은 최적의 파라미터로 세팅되어 있기 때문에 기본값이 가장 좋으나 의사결정나무에서는 조금 바꿔야 할 파라미터들이 있다
# random_state는 섞임을 고정하기 위해 지정해준다

dtr.fit(X_train, y_train)

pred1 = dtr.predict(X_test)

sns.scatterplot(x=y_test, y=pred1)

from sklearn.metrics import mean_squared_error

mean_squared_error(y_test, pred1, squared=False)

"""# **3. 선형 회귀 vs 의사 결정 나무**"""

from sklearn.linear_model import LinearRegression

lr = LinearRegression()

lr.fit(X_train, y_train)

pred2 = lr.predict(X_test)

sns.scatterplot(x=y_test, y=pred2)

mean_squared_error(y_test, pred2, squared=False) # RMSE

# 의사 결정 나무: 210.74186203651976
# 선형회귀: 221.1987722244733

# 하이퍼 파라미터 적용
# LinearRegression 하이퍼 파라미터는 보통 잘 튜닝하지는 않음
dtr = DecisionTreeRegressor(random_state=2024, max_depth=50, min_samples_leaf=30) # 깊이 50, 샘플 개수 30개 되면 멈추기

dtr.fit(X_train, y_train)

pred3= dtr.predict(X_test)

mean_squared_error(y_test, pred3, squared=False)

# 의사 결정 나무: 210.74186203651976
# 의사 결정 나무(하이퍼 파라미터 튜닝): 181.29247853838177
# 선형회귀: 221.1987722244733

from sklearn.tree import plot_tree # 트리를 그려주는 모듈

plt.figure(figsize=(24, 12))
plot_tree(dtr, max_depth=5, fontsize=10) # dtr의 max_depth와 다름
plt.show()
# 1번째 줄: 데이터 나누는 기준 (x[38]<=0.5면 왼쪽으로, 아니면 오른쪽으로)

plt.figure(figsize=(24, 12))
plot_tree(dtr, max_depth=5, fontsize=10, feature_names=X_train.columns) # 데이터의 컬럼명 붙이기
plt.show()
# 젤 처음 나눈 기준이 day_night_night -> 전처리를 통한 파생변수(원핫인코딩된)가 가장 중요하게 쓰이고 있음
# 전처리 중요 !!

