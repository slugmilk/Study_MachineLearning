# -*- coding: utf-8 -*-
"""14. 로지스틱 회귀.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bkIz42Mctf32GjcTsAIbIR4gc1Bz7KH7

# **1. hr 데이터셋**
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

hr_df = pd.read_csv('/content/drive/MyDrive/컴퓨터비전_시즌2/3. 데이터 분석/Data/hr.csv') # 승진 데이터
hr_df.head()

hr_df.info()

"""* employee_id: 임의의 직원 아이디
* department: 부서
* region: 지역
* education: 학력
* gender: 성별
* recruitment_channel: 채용 방법
* no_of_trainings: 트레이닝 받은 횟수
* age: 나이
* previous_year_rating: 이전 년도 고과 점수
* length_of_service: 근속 년수
* awards_won: 수상 경력
* avg_training_score: 평균 고과 점수
* is_promoted: 승진 여부
"""

# 승진 여부 분류하기
hr_df.describe()

sns.barplot(x='previous_year_rating', y='is_promoted', data=hr_df) # 고가점수와 승진 여부 관계

sns.lineplot(x='previous_year_rating', y='is_promoted', data=hr_df) # 선그래프로도 확인해보기

sns.lineplot(x='avg_training_score', y='is_promoted', data=hr_df) # 평균 트레이닝 점수

sns.barplot(x='recruitment_channel', y='is_promoted', data=hr_df)

hr_df['recruitment_channel'].value_counts() # referred가 승진을 많이 해 보이지만, 데이터가 너무 작고 편차가 큼

sns.barplot(x='gender', y='is_promoted', data=hr_df)

hr_df['gender'].value_counts()

sns.barplot(x='department', y='is_promoted', data=hr_df)

hr_df['department'].value_counts()

plt.figure(figsize=(12, 9))
sns.barplot(x='region', y='is_promoted', data=hr_df)
plt.xticks(rotation=45)

hr_df['region'].value_counts()

hr_df.isna().mean()

hr_df['education'].value_counts()

hr_df['previous_year_rating'].value_counts()

# 두 데이터 모두 결측치가 많지도 않고 딱히 뭘 채우기도 애매해서 걍 제거
hr_df = hr_df.dropna()

hr_df.info() # 결측치 없는지 확인

for i in ['department', 'region', 'education', 'gender', 'recruitment_channel']:
  print(i, hr_df[i].nunique())

# 지역 제외(너무 많고 별로 쓸데 없어 보여서..) 나머지 원핫인코딩
hr_df = pd.get_dummies(hr_df, columns=['department', 'education', 'gender', 'recruitment_channel'])

hr_df.head()

# 쓸모없는 것 지우기
hr_df.drop(['employee_id', 'region'], axis=1, inplace=True)
hr_df.head()

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(hr_df.drop('is_promoted', axis=1), hr_df['is_promoted'], test_size=0.2, random_state=2024)

X_train.shape, y_train.shape

X_test.shape, y_train.shape

"""# **2. 로지스틱 회귀(Logistic Regression)**
* 둘 중의 하나를 결정하는 문제(이진 분류)를 풀기 위한 대표적인 알고리즘
* 이진 분류에 적합하지만, 다항 분류 문제에도 확장될 수 있음
* 예측(x) 분류(o)
* 종속 변수 Y는 두 가지 범주 중 하나를 가짐(예: 0 또는 1)
* 특정 범주의 속할 확률을 예측하는 것이 목표

<img src='https://velog.velcdn.com/images/zlddp723/post/ce2bc937-d8dd-4d4f-8c22-e7baf8dcd8ce/image.png'>

> 로지스틱 회귀 모델은 일반화 선형 모델의 일종으로, 독립 변수의 선형 조합을 로지스틱 함수(시그모이드 함수)를 사용하여 종속 변수에 대한 확률 점수로 변환 (0~1)

확률에 따라 0과 1로 분류하는데 임계값 설정을 통해 0과 1로 나누는 기준을 정해줄 수 있음
"""

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()

lr.fit(X_train, y_train) # 학습

pred = lr.predict(X_test) # 예측

from sklearn.metrics import accuracy_score

accuracy_score(y_test, pred) # 정확도: 92% -> 꽤 괜~
# 예측 문제면 92% ok. 하지만 분류에서는 ..

# 데이터 쏠림 현상에 의해 학습이 제대로 안됐는데 정확도가 높은 것인지 학습이 제대로 돼서 정확도가 높은 것인지 확인 필요
# accuracy_score 만으로는 확인 할 수 없음
hr_df['is_promoted'].value_counts()

"""# **3. 혼돈 행렬(confusion matrix)**
* 정밀도와 재현율(민감도)를 활용하는 평가용 지수
"""

from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, pred)

"""```
  TN(8784)  FP(100)
  FN(673)   TP(175)
```
T: true
F: false
P: positive
N: negative

* TN(진양성): 승진하지 못했는데, 승진하지 못했다고 예측해서 맞춤
* FP(위양성): 승진하지 못했는데, 승진했다고 예측해서 틀림
* FN(위음성): 승진했는데, 승진하지 못했다고 예측해서 틀림
* TP(진양성): 승진했는데, 승진했다고 예측해서 맞춤

### 3-1. 정밀도(Precision)
* TP / (TP + FP)
* 무조건 양성으로 판단해서 계산하는 방법
* 긍정으로 예측한 것들 중에서 실제로 긍정인 비율

### 3-2. 재현율(Recall)
* TP / (TP + FN)
* 정확하게 감지한 양성 샘플의 비율
* 실제로 긍정인 것들 중에서 긍정으로 예측한 비율
* 민감도 또는 TPR(True Positive Rate) 라고도 부름

### 3-3. f1 score
* 정밀도와 재현율의 조화평균을 나타내는 지표
* 두 값이 차이가 날 수록 조화평균 값이 작아짐

```
정밀도  재현율  산술평균  조화평균
0.4     0.6     0.5       0.48
0.3     0.7     0.5       0.42
0.5     0.5     0.5       0.5
```

$$2*\frac{정밀도 * 재현율}{정밀도 + 재현율}=\frac{TP}{TP+\frac{FN+FP}{2}}$$
"""

from sklearn.metrics import precision_score, recall_score, f1_score

precision_score(y_test, pred)

recall_score(y_test, pred)

f1_score(y_test, pred)

lr.coef_ # 독립변수들의 기울기

# 독립변수
tempX = hr_df[['previous_year_rating', 'avg_training_score', 'awards_won?']]
# 종속변수
tempy = hr_df['is_promoted']

temp_lr = LogisticRegression()

temp_lr.fit(tempX, tempy)

temp_df = pd.DataFrame({
    'previous_year_rating':[4.0, 5.0, 5.0],
    'avg_training_score': [100, 90, 100],
    'awards_won?': [0, 1, 1]
}) # test 데이터

temp_df

pred = temp_lr.predict(temp_df)
pred

temp_lr.coef_ # 기울기

temp_lr.intercept_ # 절편

proba = temp_lr.predict_proba(temp_df) # 확률 확인 [0일 확률, 1일 확률]
proba

proba = temp_lr.predict_proba(temp_df)[:, 1] # 1일(승진할) 확률
proba

# 임계값 설정
threshold = 0.5 # 임계값 50%
pred = (proba >= threshold).astype(int)
pred

"""# **4. 교차 검증(Cross Validation)**
* 로지스틱에서만 교차 검증 하는 것 X
* train_test_split에서 발생하는 데이터의 섞임에 따라 성능이 좌우되는 문제를 해결하기 위한 방법
* K겹(K-Fold) 교차 검증을 가장 많이 사용
"""

from sklearn.model_selection import KFold

kf = KFold(n_splits=5) # n개로 쪼개서 첫번째를 test, 나머지를 train으로 -> 두번째를 test, 나머지를 train -> ... -> 5번 반복 후 평균 내서 확인
kf

hr_df

# 앞에서 split한 만큼 돌면서(5번) train데이터의 인덱스, test데이터의 인덱스, train데이터의 개수, test데이터의 개수 출력
for train_index, test_index in kf.split(range(len(hr_df))):
  print(train_index, test_index, len(train_index), len(test_index))
# kf.split(range(len(hr_df))): 전체 데이터프레임의 데이터 개수를 앞에 split 한 만큼 쪼갬
# 근데 출력된 거 보면 데이터가 안섞여있음

# 데이터 섞어서 하기
kf = KFold(n_splits=5, random_state=2024, shuffle=True) # shuffle=True 해줘야 데이터가 섞임

for train_index, test_index in kf.split(range(len(hr_df))):
  print(train_index, test_index, len(train_index), len(test_index))

acc_list = []

for train_index, test_index in kf.split(range(len(hr_df))):
  X = hr_df.drop('is_promoted', axis=1)
  y= hr_df['is_promoted']

  X_train = X.iloc[train_index]
  X_test = X.iloc[test_index]
  y_train = y.iloc[train_index]
  y_test = y.iloc[test_index]

  lr = LogisticRegression()
  lr.fit(X_train, y_train)
  pred = lr.predict(X_test)
  acc_list.append(accuracy_score(y_test, pred))

acc_list

np.array(acc_list).mean()

"""> 크로스벨리데이션을 사용하는 이유는 경과를 좋게 하기 위함이 아니라, 믿을만한 검증을 하기 위함"""